"""Transform Document Tool for AI operations.

Provides document transformation capabilities including character renaming,
setting changes, style rewrites, and custom transformations.
Uses subagents for parallel chunk processing of large documents.
"""

from __future__ import annotations

import asyncio
import logging
import re
import uuid
from dataclasses import dataclass, field
from enum import Enum, auto
from typing import Any, ClassVar, Coroutine, Protocol

from .base import SubagentTool, ToolContext
from .errors import (
    ContentRequiredError,
    InvalidParameterError,
    TabNotFoundError,
    ToolError,
)
from .subagent import (
    ChunkCoordinator,
    ChunkSpec,
    SubagentOrchestrator,
    SubagentResult,
    SubagentTask,
    SubagentType,
    TaskPriority,
    TransformAggregator,
    estimate_tokens,
)
from .version import VersionToken

LOGGER = logging.getLogger(__name__)


# =============================================================================
# Transformation Types
# =============================================================================


class TransformationType(Enum):
    """Type of document transformation to perform."""

    CHARACTER_RENAME = "character_rename"  # Rename a character
    SETTING_CHANGE = "setting_change"  # Change setting/location
    STYLE_REWRITE = "style_rewrite"  # Rewrite in different style
    TENSE_CHANGE = "tense_change"  # Change narrative tense
    POV_CHANGE = "pov_change"  # Change point of view
    CUSTOM = "custom"  # Custom transformation


class OutputMode(Enum):
    """How to output transformation results."""

    NEW_TAB = "new_tab"  # Create a new tab with transformed content
    IN_PLACE = "in_place"  # Replace content in current tab (requires version)
    PREVIEW = "preview"  # Return preview without applying


# Transformation instructions
TRANSFORM_INSTRUCTIONS = {
    TransformationType.CHARACTER_RENAME: """Transform this text chunk by renaming a character.

Instructions:
- Replace all occurrences of "{old_name}" with "{new_name}"
- Update pronouns if specified: {pronoun_update}
- Maintain possessive forms (e.g., "{old_name}'s" â†’ "{new_name}'s")
- Handle name variations (nicknames, titles) if provided
- Preserve formatting and surrounding context

Return as JSON:
{{
    "transformed_content": "string with renamed character",
    "replacements": number,
    "locations": [line_numbers]
}}""",

    TransformationType.SETTING_CHANGE: """Transform this text chunk by changing the setting/location.

Instructions:
- Change references from "{old_setting}" to "{new_setting}"
- Update related cultural details: {cultural_details}
- Adapt descriptions, landmarks, customs as appropriate
- Maintain narrative consistency

Return as JSON:
{{
    "transformed_content": "string with changed setting",
    "replacements": number,
    "adaptations": ["list of cultural adaptations made"]
}}""",

    TransformationType.STYLE_REWRITE: """Rewrite this text chunk in a different style.

Target style: {target_style}
Style guidelines: {style_guidelines}

Instructions:
- Maintain the same plot/events/information
- Adapt vocabulary, sentence structure, and tone to match target style
- Preserve character voices where appropriate
- Keep the same overall length (within 20%)

Return as JSON:
{{
    "transformed_content": "string in new style",
    "style_changes": ["list of key style changes made"]
}}""",

    TransformationType.TENSE_CHANGE: """Transform this text chunk by changing the narrative tense.

From: {from_tense}
To: {to_tense}

Instructions:
- Convert all narrative verbs from {from_tense} to {to_tense} tense
- Keep dialogue unchanged (only change narrative/prose)
- Maintain temporal relationships (before/after events)
- Handle irregular verbs correctly

Return as JSON:
{{
    "transformed_content": "string in new tense",
    "verbs_changed": number
}}""",

    TransformationType.POV_CHANGE: """Transform this text chunk by changing the point of view.

From: {from_pov}
To: {to_pov}
Focal character: {focal_character}

Instructions:
- Change pronouns and perspective accordingly
- Adjust internal thoughts/feelings to match new POV
- Handle scene information appropriately (limited POV can't know others' thoughts)
- Maintain narrative consistency

Return as JSON:
{{
    "transformed_content": "string in new POV",
    "pov_adjustments": ["list of key POV changes made"]
}}""",
}


# =============================================================================
# Document Editor Protocol
# =============================================================================


class TransformDocumentEditor(Protocol):
    """Protocol for editing document content."""

    def set_document_text(self, tab_id: str, new_text: str) -> None:
        """Set the complete text content of a document."""
        ...

    def create_document(self, title: str, content: str) -> str | None:
        """Create a new document and return its tab ID."""
        ...


# =============================================================================
# Character Rename Helper
# =============================================================================


@dataclass
class CharacterRenameSpec:
    """Specification for character renaming."""

    old_name: str
    new_name: str
    aliases: list[str] = field(default_factory=list)
    update_pronouns: bool = False
    old_pronouns: dict[str, str] = field(default_factory=dict)  # he->she, his->her
    new_pronouns: dict[str, str] = field(default_factory=dict)


def find_character_mentions(
    text: str,
    name: str,
    aliases: list[str] | None = None,
) -> list[tuple[int, int, str]]:
    """Find all mentions of a character in text.

    Args:
        text: The text to search.
        name: Primary character name.
        aliases: Alternative names/nicknames.

    Returns:
        List of (start, end, matched_text) tuples.
    """
    mentions = []
    all_names = [name] + (aliases or [])

    for search_name in all_names:
        # Match whole words, including possessive forms
        pattern = re.compile(
            rf"\b{re.escape(search_name)}(?:'s?)?\b",
            re.IGNORECASE,
        )
        for match in pattern.finditer(text):
            mentions.append((match.start(), match.end(), match.group()))

    # Sort by position and deduplicate overlapping
    mentions.sort(key=lambda x: x[0])
    return mentions


def apply_character_rename(
    text: str,
    spec: CharacterRenameSpec,
) -> tuple[str, int]:
    """Apply character renaming to text.

    Args:
        text: The text to transform.
        spec: Rename specification.

    Returns:
        Tuple of (transformed_text, replacement_count).
    """
    replacements = 0
    result = text

    # Build replacement patterns
    patterns = [(spec.old_name, spec.new_name)]
    for alias in spec.aliases:
        # Map alias to new name (simple approach)
        patterns.append((alias, spec.new_name))

    for old, new in patterns:
        # Handle possessive
        old_poss = f"{old}'s"
        new_poss = f"{new}'s"

        # Count replacements
        count = len(re.findall(rf"\b{re.escape(old)}\b", result, re.IGNORECASE))
        count += len(re.findall(rf"\b{re.escape(old_poss)}\b", result, re.IGNORECASE))

        # Apply replacements
        result = re.sub(
            rf"\b{re.escape(old_poss)}\b",
            new_poss,
            result,
            flags=re.IGNORECASE,
        )
        result = re.sub(
            rf"\b{re.escape(old)}\b",
            new,
            result,
            flags=re.IGNORECASE,
        )

        replacements += count

    # Handle pronoun updates if requested
    if spec.update_pronouns:
        for old_pron, new_pron in spec.old_pronouns.items():
            new_val = spec.new_pronouns.get(old_pron, new_pron)
            count = len(re.findall(rf"\b{re.escape(old_pron)}\b", result, re.IGNORECASE))
            result = re.sub(
                rf"\b{re.escape(old_pron)}\b",
                new_val,
                result,
                flags=re.IGNORECASE,
            )
            replacements += count

    return result, replacements


# =============================================================================
# Transform Document Tool
# =============================================================================


@dataclass
class TransformDocumentTool(SubagentTool):
    """Tool for transforming document content using subagents.

    Performs document transformations with automatic chunking for large documents.
    Supports multiple transformation types that process chunks in parallel.

    Parameters:
        tab_id: Target tab ID (optional, defaults to active tab).
        transformation_type: Type of transformation to perform.
            - "character_rename": Rename a character throughout the document
            - "setting_change": Change the setting/location
            - "style_rewrite": Rewrite in a different style
            - "tense_change": Change narrative tense
            - "pov_change": Change point of view
            - "custom": Custom transformation (requires custom_prompt)

        For character_rename:
            - old_name: Current character name (required)
            - new_name: New character name (required)
            - aliases: List of alternative names/nicknames to also rename
            - update_pronouns: Whether to update pronouns (default False)
            - pronoun_map: Mapping of old pronouns to new pronouns

        For setting_change:
            - old_setting: Current setting name (required)
            - new_setting: New setting name (required)
            - cultural_details: Specific cultural adaptations to make

        For style_rewrite:
            - target_style: Target writing style (e.g., "formal", "casual", "noir")
            - style_guidelines: Additional style guidelines

        For tense_change:
            - from_tense: Current tense (e.g., "past", "present")
            - to_tense: Target tense

        For pov_change:
            - from_pov: Current POV (e.g., "first", "third-limited", "third-omniscient")
            - to_pov: Target POV
            - focal_character: Character for limited POV focus

        For custom:
            - custom_prompt: Custom transformation instructions (required)

        output_mode: How to output results.
            - "new_tab": Create new tab with transformed content (default)
            - "in_place": Replace content in current tab (requires version)
            - "preview": Return preview without applying

        version: Version token (required if output_mode="in_place")
        output_tab_title: Title for new output tab (optional)

    Returns:
        status: "complete" or "partial"
        chunks_processed: Number of chunks transformed
        total_replacements: Total number of replacements made
        output_tab_id: ID of output tab (if new_tab mode)
        version: New version token (if in_place mode)
        preview: Preview of changes (if preview mode)
    """

    name: ClassVar[str] = "transform_document"
    summarizable: ClassVar[bool] = False

    # Dependencies (injected)
    orchestrator: SubagentOrchestrator | None = None
    document_editor: TransformDocumentEditor | None = None
    chunk_coordinator: ChunkCoordinator | None = None

    def validate(self, params: dict[str, Any]) -> None:
        """Validate parameters."""
        super().validate(params)

        transform_type = params.get("transformation_type", "custom")
        valid_types = [t.value for t in TransformationType]

        if transform_type not in valid_types:
            raise InvalidParameterError(
                message=f"Invalid transformation_type: {transform_type}",
                parameter="transformation_type",
                value=transform_type,
                expected=f"one of {valid_types}",
            )

        # Type-specific validation
        if transform_type == "character_rename":
            if not params.get("old_name"):
                raise ContentRequiredError(
                    message="old_name is required for character_rename",
                    field_name="old_name",
                )
            if not params.get("new_name"):
                raise ContentRequiredError(
                    message="new_name is required for character_rename",
                    field_name="new_name",
                )

        elif transform_type == "setting_change":
            if not params.get("old_setting"):
                raise ContentRequiredError(
                    message="old_setting is required for setting_change",
                    field_name="old_setting",
                )
            if not params.get("new_setting"):
                raise ContentRequiredError(
                    message="new_setting is required for setting_change",
                    field_name="new_setting",
                )

        elif transform_type == "style_rewrite":
            if not params.get("target_style"):
                raise ContentRequiredError(
                    message="target_style is required for style_rewrite",
                    field_name="target_style",
                )

        elif transform_type == "tense_change":
            # Accept either target_tense (simpler) or from_tense/to_tense (explicit)
            has_target = bool(params.get("target_tense"))
            has_from_to = bool(params.get("from_tense") and params.get("to_tense"))
            if not has_target and not has_from_to:
                raise ContentRequiredError(
                    message="target_tense (or from_tense and to_tense) is required for tense_change",
                    field_name="target_tense",
                )

        elif transform_type == "pov_change":
            # Accept either target_pov (simpler) or from_pov/to_pov (explicit)
            has_target = bool(params.get("target_pov"))
            has_from_to = bool(params.get("from_pov") and params.get("to_pov"))
            if not has_target and not has_from_to:
                raise ContentRequiredError(
                    message="target_pov (or from_pov and to_pov) is required for pov_change",
                    field_name="target_pov",
                )

        elif transform_type == "custom":
            if not params.get("custom_prompt"):
                raise ContentRequiredError(
                    message="custom_prompt is required for custom transformation",
                    field_name="custom_prompt",
                )

        # Validate output mode
        output_mode = params.get("output_mode", "new_tab")
        valid_modes = [m.value for m in OutputMode]
        if output_mode not in valid_modes:
            raise InvalidParameterError(
                message=f"Invalid output_mode: {output_mode}",
                parameter="output_mode",
                value=output_mode,
                expected=f"one of {valid_modes}",
            )

        if output_mode == "in_place" and not params.get("version"):
            raise ContentRequiredError(
                message="version token is required for in_place output_mode",
                field_name="version",
            )

    def execute(
        self,
        context: ToolContext,
        params: dict[str, Any],
    ) -> dict[str, Any] | Coroutine[Any, Any, dict[str, Any]]:
        """Execute document transformation.

        Overrides the base SubagentTool.execute to use async orchestrator
        when available for LLM-based transformations. Character rename
        transformations are handled locally without LLM.
        """
        # Plan the work
        tasks = self.plan(context, params)
        if not tasks:
            return {"status": "no_tasks", "results": []}

        transform_type_str = params.get("transformation_type", "custom")
        transform_type = TransformationType(transform_type_str)

        # Build chunk ordering for content reassembly
        chunk_order = self._build_chunk_order(tasks)
        
        # Get output mode
        output_mode_str = params.get("output_mode", "new_tab")
        output_mode = OutputMode(output_mode_str)

        # Character rename can be done locally without LLM
        if transform_type == TransformationType.CHARACTER_RENAME:
            aggregated = self._execute_sync(context, tasks, chunk_order)
            return self._apply_output_mode(context, params, aggregated, output_mode)

        # For LLM-based transformations, use async execution if orchestrator available
        if self.orchestrator and self.orchestrator._executor is not None:
            return self._execute_async(context, params, tasks, chunk_order)

        # Fall back to sync execution (which will return errors without executor)
        aggregated = self._execute_sync(context, tasks, chunk_order)
        return self._apply_output_mode(context, params, aggregated, output_mode)

    async def _execute_async(
        self,
        context: ToolContext,
        params: dict[str, Any],
        tasks: list[dict[str, Any]],
        chunk_order: list[tuple[str, int]],
    ) -> dict[str, Any]:
        """Execute transformation asynchronously using the orchestrator."""
        transform_type_str = params.get("transformation_type", "custom")
        output_mode_str = params.get("output_mode", "new_tab")
        output_mode = OutputMode(output_mode_str)

        # Convert task dicts to SubagentTask objects
        subagent_tasks = []
        for task in tasks:
            chunk: ChunkSpec = task["chunk"]
            subagent_task = SubagentTask(
                task_id=f"transform-{uuid.uuid4().hex[:8]}",
                subagent_type=SubagentType.TRANSFORMER,
                chunk=chunk,
                instructions=task["instructions"],
                priority=TaskPriority.NORMAL,
                metadata={
                    "transformation_type": transform_type_str,
                    "params": {
                        k: v for k, v in params.items()
                        if k not in ("tab_id", "version")  # Exclude non-serializable
                    },
                },
            )
            subagent_tasks.append(subagent_task)

        # Run all tasks through orchestrator
        results = await self.orchestrator.run_tasks(subagent_tasks, parallel=True)

        # Aggregate results with chunk ordering for content reassembly
        aggregated = self._aggregate_results(results, transform_type_str, chunk_order)

        # Apply output mode
        return self._apply_output_mode(context, params, aggregated, output_mode)

    def _execute_sync(
        self,
        context: ToolContext,
        tasks: list[dict[str, Any]],
        chunk_order: list[tuple[str, int]],
    ) -> dict[str, Any]:
        """Execute transformation synchronously (for local transformations)."""
        results = []
        errors = []
        for task in tasks:
            try:
                result = self.execute_subagent(context, task)
                results.append(result)
            except Exception as exc:
                LOGGER.warning("Subagent task failed: %s", exc)
                errors.append({"task": task, "error": str(exc)})

        # Aggregate results with chunk ordering
        aggregated = self._aggregate_sync_results(results, chunk_order)

        # Include error info if any
        if errors:
            aggregated["partial_errors"] = errors
            aggregated["completed"] = len(results)
            aggregated["total"] = len(tasks)

        return aggregated

    def _build_chunk_order(self, tasks: list[dict[str, Any]]) -> list[tuple[str, int]]:
        """Build chunk ordering from tasks for content reassembly.
        
        Args:
            tasks: List of task dicts, each containing a 'chunk' ChunkSpec.
        
        Returns:
            List of (chunk_id, start_char) tuples.
        """
        order = []
        for task in tasks:
            chunk: ChunkSpec = task["chunk"]
            order.append((chunk.chunk_id, chunk.start_char))
        return order

    def _aggregate_sync_results(
        self,
        results: list[dict[str, Any]],
        chunk_order: list[tuple[str, int]],
    ) -> dict[str, Any]:
        """Aggregate sync execution results with content reassembly."""
        # Convert dict results to SubagentResult objects
        subagent_results = []
        for r in results:
            if isinstance(r, SubagentResult):
                subagent_results.append(r)
            else:
                subagent_results.append(SubagentResult(
                    task_id=r.get("task_id", "unknown"),
                    success=r.get("success", False),
                    output=r.get("output", {}),
                    error=r.get("error"),
                    chunk_id=r.get("chunk_id", ""),
                    tokens_used=r.get("tokens_used", 0),
                ))

        # Use the transform aggregator with chunk ordering
        aggregator = TransformAggregator()
        return aggregator.aggregate(subagent_results, chunk_order)

    def _aggregate_results(
        self,
        results: list[SubagentResult],
        transformation_type: str,
        chunk_order: list[tuple[str, int]],
    ) -> dict[str, Any]:
        """Aggregate SubagentResult objects into final output."""
        aggregator = TransformAggregator()
        aggregated = aggregator.aggregate(results, chunk_order)

        # Add transformation-specific summary
        successful = [r for r in results if r.success]
        failed = [r for r in results if not r.success]

        aggregated["status"] = "complete" if not failed else "partial"
        aggregated["chunks_processed"] = len(successful)
        aggregated["chunks_failed"] = len(failed)

        # Include errors if any
        if failed:
            aggregated["errors"] = [
                {"chunk_id": r.chunk_id, "error": r.error}
                for r in failed
            ]

        return aggregated

    def _apply_output_mode(
        self,
        context: ToolContext,
        params: dict[str, Any],
        aggregated: dict[str, Any],
        output_mode: OutputMode,
    ) -> dict[str, Any]:
        """Apply output mode to the aggregated transformation results.
        
        Args:
            context: Tool execution context.
            params: Original tool parameters.
            aggregated: Aggregated transformation results including transformed_content.
            output_mode: How to output the results.
        
        Returns:
            Updated aggregated result with output mode applied.
        """
        transformed_content = aggregated.get("transformed_content")
        
        # If transformation failed or no content, return as-is
        if aggregated.get("status") != "complete" or transformed_content is None:
            LOGGER.debug(
                "Cannot apply output_mode=%s: status=%s, has_content=%s",
                output_mode.value,
                aggregated.get("status"),
                transformed_content is not None,
            )
            return aggregated
        
        if output_mode == OutputMode.PREVIEW:
            # Preview mode: just return the content without applying
            aggregated["preview"] = transformed_content
            # Remove transformed_content from output to keep it clean
            # (preview is the explicit field for this mode)
            return aggregated
        
        if output_mode == OutputMode.NEW_TAB:
            return self._apply_new_tab_mode(context, params, aggregated, transformed_content)
        
        if output_mode == OutputMode.IN_PLACE:
            return self._apply_in_place_mode(context, params, aggregated, transformed_content)
        
        # Unknown mode, just return
        LOGGER.warning("Unknown output_mode: %s", output_mode)
        return aggregated

    def _apply_new_tab_mode(
        self,
        context: ToolContext,
        params: dict[str, Any],
        aggregated: dict[str, Any],
        transformed_content: str,
    ) -> dict[str, Any]:
        """Create a new tab with the transformed content."""
        if self.document_editor is None:
            LOGGER.warning("Cannot create new tab: document_editor not configured")
            aggregated["output_mode_error"] = "document_editor not configured"
            return aggregated
        
        # Generate a title for the new tab
        transform_type = params.get("transformation_type", "transformed")
        source_tab_id = params.get("tab_id", "unknown")
        title = f"{source_tab_id} ({transform_type})"
        
        try:
            new_tab_id = self.document_editor.create_document(title, transformed_content)
            if new_tab_id:
                aggregated["output_tab_id"] = new_tab_id
                LOGGER.info(
                    "Created new tab %s with transformed content (%d chars)",
                    new_tab_id,
                    len(transformed_content),
                )
            else:
                aggregated["output_mode_error"] = "Failed to create new tab"
                LOGGER.warning("create_document returned None")
        except Exception as exc:
            LOGGER.exception("Failed to create new tab: %s", exc)
            aggregated["output_mode_error"] = f"Failed to create new tab: {exc}"
        
        return aggregated

    def _apply_in_place_mode(
        self,
        context: ToolContext,
        params: dict[str, Any],
        aggregated: dict[str, Any],
        transformed_content: str,
    ) -> dict[str, Any]:
        """Apply transformation in-place to the source document."""
        if self.document_editor is None:
            LOGGER.warning("Cannot apply in-place: document_editor not configured")
            aggregated["output_mode_error"] = "document_editor not configured"
            return aggregated
        
        tab_id = context.require_tab_id(params.get("tab_id"))
        
        try:
            self.document_editor.set_document_text(tab_id, transformed_content)
            # Note: A new version token should be obtained after the edit
            # For now, we just mark it as applied
            aggregated["applied_in_place"] = True
            LOGGER.info(
                "Applied transformation in-place to tab %s (%d chars)",
                tab_id,
                len(transformed_content),
            )
        except Exception as exc:
            LOGGER.exception("Failed to apply in-place: %s", exc)
            aggregated["output_mode_error"] = f"Failed to apply in-place: {exc}"
        
        return aggregated

    def plan(
        self,
        context: ToolContext,
        params: dict[str, Any],
    ) -> list[dict[str, Any]]:
        """Plan transformation tasks for document chunks."""
        # Resolve tab ID
        tab_id = context.require_tab_id(params.get("tab_id"))

        # Get document content
        content = context.document_provider.get_document_content(tab_id)
        if content is None:
            raise TabNotFoundError(
                message=f"Document not found: {tab_id}",
                tab_id=tab_id,
            )

        # Parse transformation type
        transform_type_str = params.get("transformation_type", "custom")
        transform_type = TransformationType(transform_type_str)

        # Build instructions based on type
        instructions = self._build_instructions(transform_type, params)

        # Create chunk coordinator
        coordinator = self.chunk_coordinator or ChunkCoordinator()

        # Create chunks
        if coordinator.should_chunk(content):
            chunks = coordinator.create_chunks(content, tab_id)
            LOGGER.info(
                "Document chunked into %d pieces for transformation (type=%s)",
                len(chunks),
                transform_type.value,
            )
        else:
            # Single chunk for small documents
            chunks = [ChunkSpec(
                chunk_id=f"{tab_id}-chunk-0",
                document_id=tab_id,
                content=content,
                start_char=0,
                end_char=len(content),
                token_estimate=estimate_tokens(content),
            )]

        # Convert to task specs
        tasks = []
        for chunk in chunks:
            tasks.append({
                "chunk": chunk,
                "transformation_type": transform_type,
                "instructions": instructions,
                "params": params,  # Pass original params for type-specific handling
            })

        return tasks

    def aggregate(self, results: list[dict[str, Any]]) -> dict[str, Any]:
        """Aggregate transformation results from all chunks.
        
        This is the abstract method implementation required by SubagentTool.
        It delegates to _aggregate_sync_results without chunk ordering,
        which means transformed_content won't be reassembled.
        For full content reassembly, use _aggregate_sync_results directly.
        """
        # Without chunk ordering, we can't reassemble content
        return self._aggregate_sync_results(results, chunk_order=[])

    def execute_subagent(
        self,
        context: ToolContext,
        task: dict[str, Any],
    ) -> dict[str, Any]:
        """Execute transformation on a single chunk."""
        chunk: ChunkSpec = task["chunk"]
        transform_type: TransformationType = task["transformation_type"]
        params: dict[str, Any] = task["params"]

        # For character_rename, we can do local transformation
        if transform_type == TransformationType.CHARACTER_RENAME:
            return self._transform_character_rename(chunk, params)

        # For other types, create subagent task
        subagent_task = SubagentTask(
            task_id=f"transform-{uuid.uuid4().hex[:8]}",
            subagent_type=SubagentType.TRANSFORMER,
            chunk=chunk,
            instructions=task["instructions"],
            priority=TaskPriority.NORMAL,
        )

        # Fallback path: orchestrator exists but executor not available
        # This should rarely happen as async execution is the primary path
        if self.orchestrator:
            # Sync execution through orchestrator is not supported
            LOGGER.warning(
                "transform_document: orchestrator exists but no executor for sync execution. "
                "Task %s for chunk %s with type '%s' cannot be executed via sync path.",
                subagent_task.task_id,
                chunk.chunk_id,
                transform_type.value,
            )
            return {
                "task_id": subagent_task.task_id,
                "success": False,
                "chunk_id": chunk.chunk_id,
                "error": f"Transformation type '{transform_type.value}' requires async execution path. "
                         "Ensure orchestrator has an executor configured.",
                "output": {},
                "tokens_used": 0,
            }

        # No orchestrator - return error indicating the feature isn't ready
        return {
            "task_id": subagent_task.task_id,
            "success": False,
            "chunk_id": chunk.chunk_id,
            "error": f"Transformation type '{transform_type.value}' requires subagent execution which is not yet configured. "
                     "Only 'character_rename' transformations are currently supported.",
            "output": {},
            "tokens_used": 0,
        }

    def _transform_character_rename(
        self,
        chunk: ChunkSpec,
        params: dict[str, Any],
    ) -> dict[str, Any]:
        """Perform character rename transformation locally."""
        spec = CharacterRenameSpec(
            old_name=params["old_name"],
            new_name=params["new_name"],
            aliases=params.get("aliases", []),
            update_pronouns=params.get("update_pronouns", False),
            old_pronouns=params.get("pronoun_map", {}).get("old", {}),
            new_pronouns=params.get("pronoun_map", {}).get("new", {}),
        )

        transformed, count = apply_character_rename(chunk.content, spec)

        return {
            "task_id": f"rename-{uuid.uuid4().hex[:8]}",
            "success": True,
            "chunk_id": chunk.chunk_id,
            "output": {
                "transformation_type": "character_rename",
                "transformed_content": transformed,
                "replacements": count,
            },
            "tokens_used": 0,  # Local transformation, no LLM tokens
        }

    def _build_instructions(
        self,
        transform_type: TransformationType,
        params: dict[str, Any],
    ) -> str:
        """Build instructions for the transformation."""
        if transform_type == TransformationType.CUSTOM:
            return params["custom_prompt"]

        template = TRANSFORM_INSTRUCTIONS.get(transform_type, "")
        if not template:
            return ""

        # Format template with params
        format_args = {}

        if transform_type == TransformationType.CHARACTER_RENAME:
            format_args = {
                "old_name": params.get("old_name", ""),
                "new_name": params.get("new_name", ""),
                "pronoun_update": "Update pronouns accordingly" if params.get("update_pronouns") else "Keep pronouns unchanged",
            }

        elif transform_type == TransformationType.SETTING_CHANGE:
            format_args = {
                "old_setting": params.get("old_setting", ""),
                "new_setting": params.get("new_setting", ""),
                "cultural_details": params.get("cultural_details", "Adapt as appropriate"),
            }

        elif transform_type == TransformationType.STYLE_REWRITE:
            format_args = {
                "target_style": params.get("target_style", ""),
                "style_guidelines": params.get("style_guidelines", ""),
            }

        elif transform_type == TransformationType.TENSE_CHANGE:
            # Support both target_tense (infer from) and explicit from_tense/to_tense
            to_tense = params.get("to_tense") or params.get("target_tense", "")
            from_tense = params.get("from_tense", "")
            # If only target_tense provided, infer the opposite as from_tense
            if not from_tense and to_tense:
                from_tense = "present" if to_tense == "past" else "past"
            format_args = {
                "from_tense": from_tense,
                "to_tense": to_tense,
            }

        elif transform_type == TransformationType.POV_CHANGE:
            # Support both target_pov (infer from) and explicit from_pov/to_pov
            to_pov = params.get("to_pov") or params.get("target_pov", "")
            from_pov = params.get("from_pov", "")
            # If only target_pov provided, use "unknown" as from_pov (AI will detect)
            if not from_pov and to_pov:
                from_pov = "current"
            format_args = {
                "from_pov": from_pov,
                "to_pov": to_pov,
                "focal_character": params.get("focal_character", "the protagonist"),
            }

        try:
            return template.format(**format_args)
        except KeyError:
            return template


# =============================================================================
# Consistency Checking
# =============================================================================


@dataclass
class ConsistencyIssue:
    """Represents a consistency issue found during transformation."""

    issue_type: str  # "name_conflict", "pronoun_mismatch", "context_break"
    description: str
    location: tuple[int, int]  # (start_char, end_char)
    severity: str  # "warning", "error"
    suggestion: str = ""


def check_transformation_consistency(
    original: str,
    transformed: str,
    transform_type: TransformationType,
) -> list[ConsistencyIssue]:
    """Check for consistency issues in transformed content.

    Args:
        original: Original document content.
        transformed: Transformed content.
        transform_type: Type of transformation performed.

    Returns:
        List of consistency issues found.
    """
    issues: list[ConsistencyIssue] = []

    # Check for significant length changes
    original_len = len(original)
    transformed_len = len(transformed)
    length_ratio = transformed_len / max(1, original_len)

    if length_ratio < 0.5 or length_ratio > 2.0:
        issues.append(ConsistencyIssue(
            issue_type="length_change",
            description=f"Significant length change: {length_ratio:.0%} of original",
            location=(0, transformed_len),
            severity="warning",
            suggestion="Review transformation for unintended content loss or addition",
        ))

    # Check for orphaned quotes (basic check)
    original_quotes = original.count('"') + original.count("'")
    transformed_quotes = transformed.count('"') + transformed.count("'")

    if abs(original_quotes - transformed_quotes) > original_quotes * 0.2:
        issues.append(ConsistencyIssue(
            issue_type="quote_imbalance",
            description="Significant change in quote count may indicate dialogue issues",
            location=(0, transformed_len),
            severity="warning",
            suggestion="Review dialogue sections for completeness",
        ))

    return issues


__all__ = [
    "TransformDocumentTool",
    "TransformationType",
    "OutputMode",
    "CharacterRenameSpec",
    "ConsistencyIssue",
    "find_character_mentions",
    "apply_character_rename",
    "check_transformation_consistency",
]
